#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Thu Mar 21 23:52:25 2019

@author: fawaz
"""

import numpy as np
import matplotlib.pyplot as plt
import cv2


#would_be a func for hand processeing relt time
def frame_process(frame):
    
    blurred=cv2.medianBlur(frame,5)
    kernel=np.ones((3,3),np.uint8)
    
    gray=cv2.cvtColor(blurred,cv2.COLOR_RGB2GRAY)

    th2=cv2.adaptiveThreshold(gray,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,15,3)

    dil=cv2.dilate(th2,kernel,iterations=2)
    
    
    return dil
        




#model creating 
from keras.models import Sequential
from keras.layers import Activation,Dropout,Flatten,Conv2D,MaxPooling2D,Dense
from keras.layers import LeakyReLU


model=Sequential()

model.add(Conv2D(filters=32,kernel_size=(3,3),input_shape=(300,300,1)))
model.add(LeakyReLU(alpha=0.1))

model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(filters=64,kernel_size=(3,3),input_shape=(300,300,1)))
model.add(LeakyReLU(alpha=0.1))

model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(filters=64,kernel_size=(3,3),input_shape=(300,300,1)))
model.add(LeakyReLU(alpha=0.1))

model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())

model.add(Dense(128))
model.add(LeakyReLU(alpha=0.1))

#or model.add(Activation('relu'))

model.add(Dropout(0.5))

model.add(Dense(6,activation='softmax'))

model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])


#model.summary()

from keras.preprocessing.image import ImageDataGenerator

imggen=ImageDataGenerator(rotation_range=30,
                          width_shift_range=0.1,
                          height_shift_range=0.1,
                          rescale=1/255,
                          shear_range=0.2,
                          zoom_range=0.2,
                          horizontal_flip=True,
                          fill_mode='nearest')


#####preprocessing

train_images=imggen.flow_from_directory('/Users/fawaz/Desktop/JCV/fing_count/train',
                                        target_size=(300,300),
                                        batch_size=16,
                                        color_mode='grayscale',
                                        
                                        classes=['NONE','ONE','TWO','THREE','FOUR','FIVE'],
                                        class_mode='categorical')

test_images=imggen.flow_from_directory('/Users/fawaz/Desktop/JCV/fing_count/test',
                                        target_size=(300,300),
                                        batch_size=16,
                                        color_mode='grayscale',
                            
                                        classes=['NONE','ONE','TWO','THREE','FOUR','FIVE'],
                                        class_mode='categorical')

catags=train_images.class_indices

results=model.fit_generator(train_images,epochs=3,
                            steps_per_epoch=150,
                            validation_data=test_images,
                            validation_steps=12)











########reading and classifying video####################################


from keras.models import load_model

model=load_model('/Users/fawaz/Downloads/finger_counter_colab.h5')


####################################################

def live_frame_process(frame):

    fing=cv2.resize(frame,(300,300))
    fing=np.uint8(fing)
    
    
    fing=frame_process(fing)

    fing=fing.reshape(300,300,1)
    fing=np.expand_dims(fing,axis=0) 
    
    fing=fing/255
    
    return fing


####################################open cv realtime video capturing and prediction#####################
 
 
vidcap = cv2.VideoCapture(0)
success,frame = vidcap.read()
while success:
   
  
    # save frame as JPEG file      
  success,frame = vidcap.read()
  bounded_frame=cv2.rectangle(frame,(10,100),(600,600),(255,0,0),1)
  roi=bounded_frame[100:600,10:600]

    
  roi=live_frame_process(roi)
  #predcitin
  pred=model.predict_classes(roi)
  
  
  font=cv2.FONT_HERSHEY_SIMPLEX

  roi=roi.reshape(300,300)
  roi=cv2.resize(roi,(590,500))
  roi=np.uint8(roi)*255
  cv2.putText(roi,text=str(pred),org=(100,500),fontFace=font,fontScale=5,color=(0,0,0),thickness=4,lineType=cv2.LINE_AA)

  
  roi=cv2.cvtColor(roi,cv2.COLOR_GRAY2RGB)

  bounded_frame[100:600,10:600]=roi
  cv2.imshow('frame',bounded_frame)
  

  if cv2.waitKey(1) & 0xFF == ord('q'):
      break
#to stop catpturing videos before closing the window
vidcap.release()
cv2.destroyAllWindows()

